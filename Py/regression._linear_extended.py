# Импортируем необходимые библиотеки
import matplotlib.pyplot as plt # Библиотека для (потенциальной) визуализации
import numpy as np              # Библиотека для работы с числовыми массивами (numpy arrays)
from sklearn.linear_model import LinearRegression # Класс LinearRegression для выполнения множественной линейной регрессии

# --- Создание данных для примера из реального мира (Урожайность) ---
# Предположим, у нас есть данные по 6 участкам земли (образцам)
# и мы измеряем 6 различных факторов (признаков) для каждого участка,
# чтобы предсказать урожайность.

# X - это наша матрица признаков (независимые переменные).
# Размерность 6x6: 6 образцов (строки) и 6 признаков (столбцы).
# Каждый столбец - это отдельный признак.
# Примеры признаков:
# Столбец 0: Количество осадков (мм)
# Столбец 1: Средняя температура (°C)
# Столбец 2: Количество внесенных удобрений (кг/га)
# Столбец 3: Количество солнечных часов в день
# Столбец 4: Оценка качества почвы (например, от 1 до 5)
# Столбец 5: Наличие вредителей (например, 0 - нет, 1 - мало, 2 - много)

X = np.array([
    [150, 20, 100, 8, 4, 0], # Участок 1
    [160, 22, 120, 9, 5, 0], # Участок 2
    [140, 18, 90,  7, 3, 1], # Участок 3
    [155, 21, 110, 8, 4, 0], # Участок 4
    [145, 19, 95,  7, 4, 2], # Участок 5
    [165, 23, 125, 9, 5, 1]  # Участок 6
]) # Форма X: (6, 6)

# y - это наша целевая переменная (зависимая переменная) - Урожайность (например, ц/га).
# Это одномерный массив, соответствующий каждому образцу (участку).
y = np.array([50, 55, 40, 52, 38, 58]) # Форма y: (6,)

# В данном случае нам НЕ нужно использовать .reshape(-1, 1) для X,
# потому что X уже создан как двумерный массив нужной формы (6, 6).

# Переменные после создания:
# X: [[150, 20, 100, 8, 4, 0], ...] (тип: numpy.ndarray, форма: (6, 6))
# y: [50, 55, 40, 52, 38, 58]      (тип: numpy.ndarray, форма: (6,))

# --- Обучение модели ---
# Создаем экземпляр (объект) модели линейной регрессии.
model = LinearRegression()

# Обучаем модель на наших данных X (признаки) и y (урожайность).
# Метод .fit() теперь находит ОДНО значение пересечения (intercept)
# и ШЕСТЬ значений коэффициентов (по одному для каждого из 6 признаков).
# Модель пытается найти такие коэффициенты и пересечение, чтобы минимизировать ошибку
# при предсказании урожайности по комбинации всех 6 признаков.
model.fit(X, y)

# --- Предсказания на обучающих данных ---
# Делаем предсказания с помощью обученной модели для тех же данных X.
# y_pred будет содержать предсказанную урожайность для каждого из 6 участков
# на основе выученной модели.
# Вычисление для каждого образца i:
# y_pred_i = model.intercept_ + model.coef_[0]*X[i,0] + model.coef_[1]*X[i,1] + ... + model.coef_[5]*X[i,5]
y_pred = model.predict(X)

# Переменная после предсказания на обучающих данных:
# y_pred: массив предсказанной урожайности для каждого из 6 участков
#         (тип: numpy.ndarray, форма: (6,))

# --- Вывод параметров модели ---
# После обучения model.coef_ теперь является массивом из 6 коэффициентов,
# по одному для каждого признака.
print("Коэффициенты для каждого признака:")
# Выводим коэффициенты, соответствуя порядку признаков в X:
print(f"  Осадки     (X0): {model.coef_[0]}")
print(f"  Температура(X1): {model.coef_[1]}")
print(f"  Удобрения  (X2): {model.coef_[2]}")
print(f"  Солнце     (X3): {model.coef_[3]}")
print(f"  Почва      (X4): {model.coef_[4]}")
print(f"  Вредители  (X5): {model.coef_[5]}")

# model.intercept_ - это единственное значение пересечения.
print(f"Пересечение (свободный член): {model.intercept_}")

# Можно также посмотреть предсказания для обучающих данных рядом с фактическими значениями
print("\nФактическая vs Предсказанная урожайность на обучающих данных:")
for i in range(len(y)):
    print(f"  Участок {i+1}: Факт={y[i]:.2f}, Предсказание={y_pred[i]:.2f}")


# --- Предсказание для новой точки (нового участка) ---
# Создаем данные для нового участка с определенными значениями всех 6 признаков.
# Это должен быть двумерный массив с одной строкой (один образец) и 6 столбцами (6 признаков).
new_X = np.array([[158, 21.5, 115, 8.5, 4.5, 0.5]]) # Данные для нового участка
# Форма new_X: (1, 6)

# Делаем предсказание урожайности для этого нового участка.
# Вычисление: new_pred[0] = model.intercept_ + model.coef_[0]*new_X[0,0] + ... + model.coef_[5]*new_X[0,5]
new_pred = model.predict(new_X)

# Переменная после предсказания для новой точки:
# new_X:    [[158, 21.5, 115, 8.5, 4.5, 0.5]] (тип: numpy.ndarray, форма: (1, 6))
# new_pred: [предсказанное_значение]           (тип: numpy.ndarray, форма: (1,))

# Выводим предсказанное значение для нового участка.
print(f"\nПредсказанная урожайность для нового участка: {new_pred[0]:.2f} ц/га")

# --- Визуализация (Сложность при > 2D) ---
# При множественной линейной регрессии (>1 признака) невозможно отобразить
# исходные данные и линию регрессии на простом 2D или даже 3D графике,
# так как пространство признаков имеет 6 измерений (+ 1 измерение для целевой переменной).
# Вместо этого можно визуализировать:
# 1. Фактические значения y против предсказанных значений y (как хорошо модель попала)
# 2. Остатки (разница между фактическим и предсказанным y)
# 3. Или посмотреть на зависимость целевой переменной от каждого признака по отдельности (с осторожностью, т.к. модель использует все признаки вместе).

# Пример простой визуализации: фактическая vs предсказанная урожайность
plt.figure(figsize=(8, 6))
plt.scatter(y, y_pred, color='blue')
# Добавляем линию идеального предсказания (где y_pred == y)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.xlabel('Фактическая урожайность')
plt.ylabel('Предсказанная урожайность')
plt.title('Фактическая vs Предсказанная урожайность (Обучающие данные)')
plt.grid(True)
plt.show()

# Примечание: Предсказание для new_X=6 (как в прошлом запросе) не имеет смысла здесь,
# так как X теперь представляет собой набор из 6 различных признаков, а не одно значение.
# Чтобы сделать предсказание, нужно предоставить 6 значений признаков для нового образца.