---
Специально сломанный датасет
---

### Шаги обработки данных:

1.  **Загрузить данные:** Прочитайте файл `broken_notebooks.csv` в Pandas DataFrame.
2.  **Разведочный анализ данных (EDA):**
    * **Обнаружить проблемы:** Используйте методы Pandas (например, `.info()`, `.isnull().sum()`, `.describe()`, `.value_counts()`) и визуализации (гистограммы, ящики с усами), чтобы найти:
        * Пропущенные значения.
        * Неправильные типы данных (например, числа, хранящиеся как строки).
        * Непоследовательные форматы (например, "15.6 inches" вместо 15.6, "1TB" вместо 1024 GB).
        * Непоследовательные категориальные значения (например, "windows 10" и "Windows 10").
        * Выбросы (слишком высокие или низкие цены/веса/годы).
        * Дублирующиеся записи.

3.  **Предварительная обработка (Очистка):**
    * **Обработать пропущенные значения:** Заполните или удалите `NaN` в зависимости от столбца.
    * **Привести форматы в порядок:** Преобразуйте строки в числа (например, из "15.6 inches" в 15.6).
    * **Унифицировать данные:** Сделайте так, чтобы похожие значения писались одинаково (например, "Windows 10").
    * **Обработать выбросы:** Решите, что делать с аномально большими или маленькими значениями.
    * **Удалить дубликаты:** Убедитесь, что каждая запись уникальна.

---

### Ожидаемый результат:

На выходе: **чистый, структурированный и готовый к анализу DataFrame**

* **Отсутствуют пропущенные значения** (или они обработаны надлежащим образом).
* **Все столбцы имеют правильный тип данных** (числа как числа, текст как текст).
* **Форматы данных стандартизированы** (например, все размеры экрана в дюймах, все хранилища в ГБ).
* **Категориальные значения унифицированы** (без разных написаний для одной и той же категории).
* **Выбросы обработаны**, и данные в целом кажутся логичными.
* **Отсутствуют дублирующиеся записи.**
